{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1866a2e5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!gpu-who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1f18cf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "from import_for_notebooks import *\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "import common_utils\n",
    "import analysis\n",
    "import analysis_utils\n",
    "from analysis import find_nearest_neighbour, scale, sort_by_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f93c5e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# in case you have your own sweep:\n",
    "# sweep_id = '3s9e7mys'\n",
    "# sweeps_dir = './data/sweeps/'\n",
    "# sweep = analysis_utils.read_sweep(sweeps_dir, sweep_id, name=None, problem='cifar10_vehicles_animals')\n",
    "# analysis_utils.download_sweep_results_from_wandb(sweep, max_runs_to_download=100)\n",
    "# X = analysis_utils.get_all_reconstruction_outputs(sweep, verbose=True)\n",
    "\n",
    "# read sweep parameters\n",
    "sweep = common_utils.common.load_dict_to_obj(\"./reconstructions/multiclass/sweep.txt\")\n",
    "# read model, data, and whatever needed\n",
    "args, Xtrn, Ytrn, ds_mean, W, model = analysis_utils.sweep_get_data_model(sweep, put_in_sweep=True, run_train_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce5d475",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Read Reconstructed Data:\n",
    "\n",
    "# \"X\" will contain a batch of all reconstructed samples (not all of them are good.. for this we need the rest of the cell)\n",
    "# Here we put reconstructed data from two diffferent runs.\n",
    "# you can use both of them or just one. (uncomment relevant parts)\n",
    "x_paths = [\n",
    "    './reconstructions/multiclass/run1_x.pth',\n",
    "    './reconstructions/multiclass/run2_x.pth'\n",
    "]\n",
    "# X = torch.load(x_paths[0])\n",
    "# X = torch.load(x_paths[1])\n",
    "X = torch.cat([torch.load(x_paths[0]), torch.load(x_paths[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafffdad",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Find \"Good\" Resonctructions:\n",
    "\n",
    "# Find Nearest Neighbour\n",
    "xx1 = find_nearest_neighbour(X, Xtrn, search='ncc2', vote='min', use_bb=False, nn_threshold=1000)\n",
    "# Scale to Images\n",
    "xx_scaled, yy_scaled = scale(xx1, Xtrn, ds_mean)\n",
    "# # Sort\n",
    "xx, yy, ssims, sort_idxs = sort_by_metric(xx_scaled, yy_scaled, sort='ssim')\n",
    "values = model(Xtrn).data\n",
    "\n",
    "# Plot\n",
    "# color_by_labels = Ytrn[sort_idxs]\n",
    "color_by_labels = None\n",
    "figpath=None\n",
    "analysis.plot_table(xx, yy, fig_elms_in_line=15, fig_lines_per_page=4, fig_type='one_above_another', color_by_labels=color_by_labels, figpath=figpath, show=True, dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf752c4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Show Weights of first Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b021088c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Show how the weights of the first layer looks like, for comparison.\n",
    "# Note that some data samples can be found in the first layer, but not as near as many that can be reconstructed using our approach.\n",
    "\n",
    "X = sweep.W.reshape(sweep.W.shape[0], 3, 32, 32) \n",
    "\n",
    "# Find Nearest Neighbour\n",
    "# xx1 = find_nearest_neighbour(X, Xtrn, search='ncc', vote='min', use_bb=False, nn_threshold=None)\n",
    "xx1 = find_nearest_neighbour(X, Xtrn, search='ncc', vote='mean', use_bb=True, nn_threshold=1.1)\n",
    "# Scale to Images\n",
    "xx_scaled, yy_scaled = scale(xx1, Xtrn, ds_mean, xx_add_ds_mean=False)\n",
    "# Sort\n",
    "xx, yy, ssims, sort_idxs = sort_by_metric(xx_scaled, yy_scaled, sort='ssim')\n",
    "# Plot\n",
    "analysis.plot_table(xx, yy, fig_elms_in_line=15, fig_lines_per_page=4, fig_type='one_above_another', color_by_labels=None, figpath=None, show=True, dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d88bc87",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}